import pandas as pd
import numpy as np
import re
import warnings
import logging
from typing import Union, IO, Dict, Tuple, Optional, List, Any, BinaryIO
from pathlib import Path
from datetime import datetime
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from statsmodels.tsa.arima.model import ARIMA
from prophet import Prophet
from io import BytesIO
import xlsxwriter
import pickle
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import hashlib
import joblib
import os

# Import des constantes depuis le fichier de configuration
from config import SERVICE_STANDARD, SERVICES_CLES

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
warnings.filterwarnings('ignore')

# Les attributs de classe SERVICE_STANDARD et SERVICES_CLES sont maintenant import√©s
# et ne sont plus d√©finis ici directement.

def mean_absolute_percentage_error(y_true, y_pred):
    """Calcule l'erreur de pourcentage absolue moyenne (MAPE)."""
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100
    return mape

def symmetric_mean_absolute_percentage_error(y_true, y_pred):
    """Calcule l'erreur de pourcentage absolue moyenne sym√©trique (sMAPE)."""
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    numerator = np.abs(y_pred - y_true)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
    
    # √âvite la division par z√©ro
    smape_values = np.zeros_like(y_true, dtype=float)
    non_zero_indices = denominator != 0
    smape_values[non_zero_indices] = numerator[non_zero_indices] / denominator[non_zero_indices]
    
    return np.mean(smape_values) * 100

class AnalytiqueSante:
    """
    Classe pour l'analyse pr√©dictive et la g√©n√©ration de rapports sur
    les donn√©es de sant√© - Version am√©lior√©e avec visualisations et caching.
    """
    # Les attributs de classe sont maintenant directement les constantes import√©es
    SERVICE_STANDARD = SERVICE_STANDARD
    SERVICES_CLES = SERVICES_CLES

    def __init__(self, services_cles: Optional[List[str]] = None, cache_dir: str = "cache_dir") -> None:
        """Initialise la classe AnalytiqueSante avec les attributs n√©cessaires."""
        self.logger = logging.getLogger(__name__)
        self.df_data: Optional[pd.DataFrame] = None
        self.predictions: Dict[str, Any] = {}
        self.annee_donnees: Optional[Union[int, str]] = None
        # Utilise self.SERVICES_CLES qui est maintenant la constante import√©e
        self.services_cles = services_cles if services_cles is not None else self.SERVICES_CLES
        self.service_counts: Dict[str, int] = {}
        self.donnees_mensuelles: Optional[pd.DataFrame] = None
        self.annee_cible: Optional[int] = None
        self.resultats_prevision: Dict[str, Any] = {}
        self.contexte_sanitaire: bool = True  # Valeur par d√©faut
        
        # Configuration du cache
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.cache_enabled = True
        self.cache_ttl_hours = 24  # Cache valide pendant 24h
        
        # Initialisation des mod√®les disponibles
        self.modeles_disponibles = {
            'Prophet': self._modele_prophet,
            'RandomForest': self._modele_random_forest,
            'ARIMA': self._modele_arima
        }

    def _generate_cache_key(self, service: str, model_type: str, data_hash: str) -> str:
        """
        G√©n√®re une cl√© de cache unique bas√©e sur le service, le type de mod√®le et les donn√©es.
        
        Args:
            service (str): Nom du service
            model_type (str): Type de mod√®le (Prophet, RandomForest, ARIMA)
            data_hash (str): Hash des donn√©es d'entra√Ænement
            
        Returns:
            str: Cl√© de cache unique
        """
        cache_key = f"{service}_{model_type}_{data_hash}"
        return hashlib.md5(cache_key.encode()).hexdigest()

    def _get_data_hash(self, df: pd.DataFrame) -> str:
        """
        G√©n√®re un hash des donn√©es pour identifier les changements.
        
        Args:
            df (pd.DataFrame): Donn√©es d'entra√Ænement
            
        Returns:
            str: Hash MD5 des donn√©es
        """
        # Utiliser les colonnes essentielles pour le hash
        data_str = f"{df['ds'].iloc[0]}_{df['ds'].iloc[-1]}_{len(df)}_{df['y'].sum():.2f}"
        return hashlib.md5(data_str.encode()).hexdigest()

    def _is_cache_valid(self, cache_file: Path) -> bool:
        """
        V√©rifie si le cache est encore valide selon le TTL.
        
        Args:
            cache_file (Path): Chemin vers le fichier de cache
            
        Returns:
            bool: True si le cache est valide, False sinon
        """
        if not cache_file.exists():
            return False
        
        # V√©rifier l'√¢ge du fichier
        file_age = datetime.now() - datetime.fromtimestamp(cache_file.stat().st_mtime)
        return file_age.total_seconds() < (self.cache_ttl_hours * 3600)

    def _load_cached_model(self, service: str, model_type: str, data_hash: str) -> Optional[Dict[str, Any]]:
        """
        Charge un mod√®le depuis le cache s'il existe et est valide.
        
        Args:
            service (str): Nom du service
            model_type (str): Type de mod√®le
            data_hash (str): Hash des donn√©es
            
        Returns:
            Optional[Dict[str, Any]]: Mod√®le en cache ou None
        """
        if not self.cache_enabled:
            return None
            
        try:
            cache_key = self._generate_cache_key(service, model_type, data_hash)
            cache_file = self.cache_dir / f"{cache_key}.joblib"
            
            if self._is_cache_valid(cache_file):
                self.logger.info(f"üì¶ Mod√®le {model_type} pour {service} charg√© depuis le cache")
                return joblib.load(cache_file)
            else:
                self.logger.info(f"‚è∞ Cache expir√© pour {model_type} - {service}")
                return None
                
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erreur lors du chargement du cache pour {model_type} - {service}: {e}")
            return None

    def _save_model_to_cache(self, service: str, model_type: str, data_hash: str, model_data: Dict[str, Any]) -> None:
        """
        Sauvegarde un mod√®le entra√Æn√© dans le cache.
        
        Args:
            service (str): Nom du service
            model_type (str): Type de mod√®le
            data_hash (str): Hash des donn√©es
            model_data (Dict[str, Any]): Donn√©es du mod√®le √† sauvegarder
        """
        if not self.cache_enabled:
            return
            
        try:
            cache_key = self._generate_cache_key(service, model_type, data_hash)
            cache_file = self.cache_dir / f"{cache_key}.joblib"
            
            # Sauvegarder le mod√®le
            joblib.dump(model_data, cache_file)
            self.logger.info(f"üíæ Mod√®le {model_type} pour {service} sauvegard√© dans le cache")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erreur lors de la sauvegarde du cache pour {model_type} - {service}: {e}")

    def _clear_expired_cache(self) -> None:
        """Nettoie le cache expir√© pour lib√©rer de l'espace."""
        try:
            expired_files = []
            for cache_file in self.cache_dir.glob("*.joblib"):
                if not self._is_cache_valid(cache_file):
                    expired_files.append(cache_file)
            
            for expired_file in expired_files:
                expired_file.unlink()
                
            if expired_files:
                self.logger.info(f"üßπ {len(expired_files)} fichiers de cache expir√©s supprim√©s")
                
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erreur lors du nettoyage du cache: {e}")

    def _get_cache_stats(self) -> Dict[str, Any]:
        """
        Retourne les statistiques du cache.
        
        Returns:
            Dict[str, Any]: Statistiques du cache
        """
        try:
            cache_files = list(self.cache_dir.glob("*.joblib"))
            total_size = sum(f.stat().st_size for f in cache_files)
            valid_files = [f for f in cache_files if self._is_cache_valid(f)]
            
            return {
                'total_files': len(cache_files),
                'valid_files': len(valid_files),
                'expired_files': len(cache_files) - len(valid_files),
                'total_size_mb': total_size / (1024 * 1024),
                'cache_dir': str(self.cache_dir)
            }
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erreur lors du calcul des stats du cache: {e}")
            return {}

    def _standardiser_nom_service(self, service_nom: str) -> str:
        """Standardise un nom de service en utilisant les expressions r√©guli√®res."""
        nom_nettoye = str(service_nom).strip()
        for pattern, standard_name in self.SERVICE_STANDARD.items():
            if re.search(pattern, nom_nettoye, re.IGNORECASE):
                return standard_name
        return nom_nettoye

    def _calculer_score_composite(self, metrics: Dict[str, Any]) -> float:
        """
        Calcule le score composite pond√©r√© pour un ensemble de m√©triques.
        Version am√©lior√©e avec bornage entre 0 et 1.
        """
        r2 = metrics.get('r2', 0)
        mae = metrics.get('mae', float('inf'))
        rmse = metrics.get('rmse', float('inf'))
        smape = metrics.get('smape', float('inf'))
        
        if pd.isna(r2) or pd.isna(mae) or pd.isna(rmse) or pd.isna(smape):
            return 0.0
        
        r2_norm = max(0, min(1, r2))
        mae_norm = 1 / (1 + mae) if mae != float('inf') else 0
        rmse_norm = 1 / (1 + rmse) if rmse != float('inf') else 0
        smape_norm = 1 / (1 + smape / 100) if smape != float('inf') else 0
        
        if self.contexte_sanitaire:
            poids = {'smape': 0.40, 'mae': 0.30, 'r2': 0.20, 'rmse': 0.10}
        else:
            poids = {'smape': 0.25, 'mae': 0.25, 'r2': 0.25, 'rmse': 0.25}
        
        score_composite = (
            poids['r2'] * r2_norm +
            poids['mae'] * mae_norm +
            poids['rmse'] * rmse_norm +
            poids['smape'] * smape_norm
        )
        
        # Am√©lioration 1: Forcer le bornage entre 0 et 1
        return max(0.0, min(1.0, score_composite))

    def _calculer_horizon_securise(self, df_service: pd.DataFrame) -> int:
        """
        Calcule l'horizon de pr√©vision de mani√®re s√©curis√©e.
        Am√©lioration 2: Calcul robuste de l'horizon.
        """
        if self.annee_cible:
            derniere_date_donnees = df_service['ds'].iloc[-1]
            annee_derniere_date = derniere_date_donnees.year
            mois_derniere_date = derniere_date_donnees.month
            
            # Calcul am√©lior√© de l'horizon
            mois_restants_annee_courante = 12 - mois_derniere_date
            annees_completes = max(0, self.annee_cible - annee_derniere_date - 1)
            horizon = mois_restants_annee_courante + (annees_completes * 12)
            
            # S'assurer que l'horizon est toujours positif
            return max(1, horizon)
        else:
            return 12

    def charger_donnees(self, data_stream: Union[str, IO[Any]], annee_cible: Optional[int] = None) -> bool:
        self.logger.info(f"D√©but du chargement des donn√©es depuis: {data_stream}")
        try:
            df = pd.read_csv(data_stream)
            self.logger.info(f"Donn√©es CSV charg√©es: {len(df)} lignes, colonnes: {list(df.columns)}")
            
            required_columns = ['date', 'SERVICE', 'valeur']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                self.logger.error(f"Colonnes manquantes: {missing_columns}")
                return False
                
            if df.empty:
                self.logger.error("Le fichier CSV est vide.")
                return False
            
            df['date'] = pd.to_datetime(df['date'])
            
            if annee_cible:
                self.annee_cible = annee_cible
                df = df[df['date'].dt.year < annee_cible].copy()
                if df.empty:
                    self.logger.error(f"Aucune donn√©e trouv√©e avant l'ann√©e cible {annee_cible}.")
                    return False
            else:
                self.annee_donnees = str(df['date'].dt.year.max())
                
            self.logger.info(f"Ann√©e de pr√©vision: {self.annee_donnees}")
            
            self.logger.info("D√©but de la pr√©paration des donn√©es")
            df['SERVICE'] = df['SERVICE'].apply(self._standardiser_nom_service)
            
            df.rename(columns={'date': 'ds', 'valeur': 'y'}, inplace=True)
            df['y'] = pd.to_numeric(df['y'], errors='coerce').fillna(0)
            
            self.df_data = df[df['SERVICE'].isin(self.SERVICES_CLES)].copy()
            
            if self.df_data.empty:
                self.logger.warning("Aucun service cl√© trouv√© dans les donn√©es apr√®s le filtrage.")
                return False
            
            self.df_data = self.df_data.sort_values(by=['SERVICE', 'ds'])
            
            self.service_counts = self.df_data['SERVICE'].value_counts().to_dict()
            self.logger.info(f"Pr√©paration termin√©e: {len(self.df_data)} points de donn√©es")
            self.logger.info(f"Services trouv√©s: {self.df_data['SERVICE'].unique().tolist()}")
            
            return True
            
        except FileNotFoundError:
            self.logger.error(f"Fichier non trouv√©: {data_stream}")
            return False
        except Exception as e:
            self.logger.error(f"Erreur lors du chargement des donn√©es: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False

    def _evaluer_modele(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, Any]:
        """
        Calcule les m√©triques de performance pour les pr√©dictions.
        """
        try:
            r2 = r2_score(y_true, y_pred)
            mae = mean_absolute_error(y_true, y_pred)
            rmse = np.sqrt(mean_squared_error(y_true, y_pred))
            mape = mean_absolute_percentage_error(y_true, y_pred)
            smape = symmetric_mean_absolute_percentage_error(y_true, y_pred)
            return {'r2': r2, 'mae': mae, 'rmse': rmse, 'mape': mape, 'smape': smape}
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erreur lors de l'√©valuation du mod√®le: {e}")
            return {'r2': None, 'mae': None, 'rmse': None, 'mape': None, 'smape': None, 'error': str(e)}

    def _modele_prophet(self, df: pd.DataFrame, horizon: int) -> Dict[str, Any]:
        """Mod√®le Prophet pour les pr√©visions."""
        try:
            m = Prophet(
                changepoint_prior_scale=0.05,
                seasonality_prior_scale=10.0
            )
            m.fit(df)
            future = m.make_future_dataframe(periods=horizon, freq='ME')
            forecast = m.predict(future)
            
            y_true = df['y']
            y_pred = forecast['yhat'][:len(y_true)]
            metrics = self._evaluer_modele(y_true, y_pred)
            
            return {'forecast': forecast, 'metrics': metrics}
        except Exception as e:
            self.logger.error(f"√âchec du mod√®le Prophet: {e}")
            return {'error': str(e), 'metrics': self._evaluer_modele([], [])}

    def _modele_random_forest(self, df: pd.DataFrame, horizon: int) -> Dict[str, Any]:
        """Mod√®le Random Forest pour les pr√©visions."""
        try:
            df['mois'] = df['ds'].dt.month
            df['annee'] = df['ds'].dt.year
            X = df[['mois', 'annee']]
            y = df['y']
            
            model = RandomForestRegressor(n_estimators=100, random_state=42)
            model.fit(X, y)
            
            future_dates = pd.date_range(start=df['ds'].iloc[-1], periods=horizon + 1, freq='ME')[1:]
            future_df = pd.DataFrame({
                'ds': future_dates,
                'mois': future_dates.month,
                'annee': future_dates.year
            })
            
            forecast_values = model.predict(future_df[['mois', 'annee']])
            forecast = future_df.copy()
            forecast['yhat'] = forecast_values
            
            y_pred = model.predict(X)
            metrics = self._evaluer_modele(y, y_pred)
            
            return {'forecast': forecast, 'metrics': metrics}
        except Exception as e:
            self.logger.error(f"√âchec du mod√®le Random Forest: {e}")
            return {'error': str(e), 'metrics': self._evaluer_modele([], [])}

    def _modele_arima(self, df: pd.DataFrame, horizon: int) -> Dict[str, Any]:
        """
        Mod√®le ARIMA pour les pr√©visions avec fallback robuste.
        Am√©lioration 3: ARIMA avec ordres multiples et gestion d'erreurs.
        """
        # Obtenir le nom du service au d√©but de la fonction
        service = df['SERVICE'].iloc[0]

        ordres_arima = [(1,1,1), (0,1,1), (2,1,1), (1,1,0), (0,1,0)]
        
        for ordre in ordres_arima:
            try:
                self.logger.info(f"Tentative ARIMA avec ordre {ordre} pour le service {service}")
                model = ARIMA(df['y'], order=ordre)
                model_fit = model.fit()
                
                # G√©n√©rer les pr√©visions
                forecast_result = model_fit.get_forecast(steps=horizon)
                forecast_df = forecast_result.summary_frame().reset_index()
                
                # Cr√©er les dates futures
                last_date = df['ds'].iloc[-1]
                future_dates = pd.date_range(start=last_date, periods=horizon + 1, freq='ME')[1:]
                
                forecast_df['ds'] = future_dates
                forecast_df = forecast_df.rename(columns={'mean': 'yhat'})
                
                # Calculer les m√©triques sur les donn√©es d'entra√Ænement
                y_true = df['y']
                y_pred = model_fit.predict(start=0, end=len(y_true)-1)
                metrics = self._evaluer_modele(y_true, y_pred)
                
                self.logger.info(f"‚úÖ ARIMA {ordre} r√©ussi pour le service {service}")
                return {'forecast': forecast_df[['ds', 'yhat']], 'metrics': metrics}
                
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è √âchec ARIMA {ordre} pour le service {service}: {e}")
                # Affiche l'erreur en clair dans le terminal pour le d√©bogage
                print(f"‚ö†Ô∏è √âchec ARIMA {ordre} pour le service {service}: {e}")
                continue
        
        # Si tous les ordres √©chouent
        self.logger.error(f"Tous les ordres ARIMA ont √©chou√© pour le service {service}")
        return {'error': "Tous les ordres ARIMA ont √©chou√©", 'metrics': self._evaluer_modele([], [])}

    def _generer_graphique_service(self, service: str, data: Dict[str, Any]) -> Optional[str]:
        """
        G√©n√®re un graphique HTML pour un service donn√©.
        Am√©lioration 4: Visualisation automatique dans le rapport.
        """
        try:
            if 'error' in data:
                return None
                
            # Donn√©es historiques
            df_hist = data['donnees_historiques']
            
            # Donn√©es de pr√©vision du meilleur mod√®le
            forecast_data = data['meilleur_modele']['forecast']
            meilleur_modele_nom = data['meilleur_modele']['nom']
            
            # Cr√©er le graphique
            fig = go.Figure()
            
            # Ajouter les donn√©es historiques
            fig.add_trace(go.Scatter(
                x=df_hist['ds'], 
                y=df_hist['y'],
                mode='lines+markers',
                name='Donn√©es Historiques',
                line=dict(color='blue', width=2)
            ))
            
            # Ajouter les pr√©visions
            fig.add_trace(go.Scatter(
                x=forecast_data['ds'], 
                y=forecast_data['yhat'],
                mode='lines+markers',
                name=f'Pr√©visions ({meilleur_modele_nom})',
                line=dict(color='red', width=2, dash='dash')
            ))
            
            # Mise en forme
            fig.update_layout(
                title=f'Pr√©visions pour {service} - Score: {data.get("score_composite", 0):.3f}',
                xaxis_title='Date',
                yaxis_title='Valeur',
                hovermode='x unified',
                height=400
            )
            
            return fig.to_html(include_plotlyjs='cdn', div_id=f"chart_{service.replace(' ', '_')}")
            
        except Exception as e:
            self.logger.error(f"Erreur g√©n√©ration graphique pour {service}: {e}")
            return None

    def calculer_previsions(self) -> Dict[str, Any]:
        """
        Calcule les pr√©visions pour chaque service en utilisant tous les mod√®les
        et s√©lectionne le meilleur bas√© sur le score composite.
        """
        if self.df_data is None or self.df_data.empty:
            self.logger.error("‚õî Donn√©es non charg√©es. Ex√©cution annul√©e.")
            return {}
            
        services = self.df_data['SERVICE'].unique()
        resultats_globaux = {}
        
        for service in services:
            df_service = self.df_data[self.df_data['SERVICE'] == service].copy()
            df_service = df_service.sort_values('ds')
            
            if len(df_service) < 12:
                self.logger.warning(f"‚ö†Ô∏è Service '{service}': donn√©es historiques insuffisantes (< 12 mois), ignor√©.")
                resultats_globaux[service] = {
                    'error': "Donn√©es historiques insuffisantes (< 12 mois)",
                    'score_composite': 0.0, # Assurer la pr√©sence de la cl√©
                    'models': {}
                }
                continue

            # Utiliser le calcul d'horizon s√©curis√©
            horizon = self._calculer_horizon_securise(df_service)
            
            resultats_service = {
                'donnees_historiques': df_service,
                'models': {},
                'meilleur_modele': None,
                'score_composite': 0.0  # Initialis√© √† 0 au lieu de -inf
            }
            
            meilleur_score = -1.0 # Utiliser une valeur n√©gative pour garantir une premi√®re s√©lection
            meilleur_modele_actuel = None
            
            for nom_modele, func_modele in self.modeles_disponibles.items():
                try:
                    modele_resultat = func_modele(df_service, horizon)
                    score = self._calculer_score_composite(modele_resultat['metrics'])
                    
                    if score > meilleur_score:
                        meilleur_score = score
                        meilleur_modele_actuel = nom_modele
                        
                    modele_resultat['score_composite'] = score
                    resultats_service['models'][nom_modele] = modele_resultat
                    
                    self.logger.info(f"‚úÖ Service: {service}, Mod√®le: {nom_modele}, Score: {score:.3f}")
                except Exception as e:
                    # G√©rer l'√©chec en stockant un score de 0.0 pour garantir la coh√©rence des donn√©es
                    resultats_service['models'][nom_modele] = {
                        'error': f"√âchec de l'ex√©cution: {str(e)}",
                        'score_composite': 0.0,
                    }
                    self.logger.warning(f"‚ö†Ô∏è √âchec du mod√®le {nom_modele} pour le service {service}: {e}")
            
            if meilleur_modele_actuel:
                resultats_service['meilleur_modele'] = {
                    'nom': meilleur_modele_actuel,
                    'forecast': resultats_service['models'][meilleur_modele_actuel]['forecast'],
                    'metrics': resultats_service['models'][meilleur_modele_actuel]['metrics']
                }
                resultats_service['score_composite'] = meilleur_score
                resultats_globaux[service] = resultats_service
                self.logger.info(f"üèÜ Meilleur mod√®le pour {service}: {meilleur_modele_actuel} avec un score de {meilleur_score:.3f}")
            else:
                resultats_globaux[service] = {
                    'error': "Aucun mod√®le n'a pu √™tre ex√©cut√© avec succ√®s.",
                    'score_composite': 0.0 # Assurer la pr√©sence de la cl√©
                }
                
        self.resultats_prevision = resultats_globaux
        return self.resultats_prevision

    def generer_rapport_excel_complet(self, output_file: BinaryIO) -> None:
        """
        G√©n√®re un rapport Excel complet avec plusieurs feuilles et graphiques HTML.
        Version am√©lior√©e avec visualisations int√©gr√©es.
        """
        if not self.resultats_prevision:
            raise ValueError("Aucun r√©sultat de pr√©vision √† g√©n√©rer.")

        with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:
            
            # Feuille 1: R√©sum√© des mod√®les
            df_resume = pd.DataFrame()
            for service, data in self.resultats_prevision.items():
                if 'error' not in data:
                    meilleur_modele_nom = data['meilleur_modele']['nom']
                    metrics = data['meilleur_modele']['metrics']
                    df_resume = pd.concat([df_resume, pd.DataFrame([{
                        "Service": service,
                        "Meilleur Mod√®le": meilleur_modele_nom,
                        "Score Composite": data.get('score_composite'),
                        "R2": metrics.get('r2'),
                        "MAE": metrics.get('mae'),
                        "RMSE": metrics.get('rmse'),
                        "sMAPE": metrics.get('smape'),
                    }])], ignore_index=True)
            
            if not df_resume.empty:
                df_resume = df_resume.sort_values('Score Composite', ascending=False)
                df_resume.to_excel(writer, sheet_name='R√©sum√© des Meilleurs Mod√®les', index=False)
            
            # Feuille 2: Comparaison de tous les mod√®les
            df_evaluation = pd.DataFrame()
            for service, data in self.resultats_prevision.items():
                if 'error' not in data:
                    for model_name, model_data in data['models'].items():
                        # G√©rer les cas o√π le mod√®le a √©chou√©
                        metrics = model_data.get('metrics', {})
                        score = model_data.get('score_composite', 0.0)
                        is_best = (model_name == data['meilleur_modele']['nom'])
                        df_evaluation = pd.concat([df_evaluation, pd.DataFrame([{
                            "Service": service,
                            "Mod√®le": model_name,
                            "Score Composite": score,
                            "S√©lectionn√©": "Oui" if is_best else "Non",
                            "R2": metrics.get('r2'),
                            "MAE": metrics.get('mae'),
                            "RMSE": metrics.get('rmse'),
                            "sMAPE": metrics.get('smape'),
                        }])], ignore_index=True)
            
            if not df_evaluation.empty:
                df_evaluation = df_evaluation.sort_values(['Service', 'Score Composite'], ascending=[True, False])
                df_evaluation.to_excel(writer, sheet_name='Comparaison Mod√®les', index=False)
            
            # Feuille 3: Pr√©visions d√©taill√©es
            df_toutes_previsions = pd.DataFrame()
            for service, data in self.resultats_prevision.items():
                if 'error' not in data:
                    df_temp = data['meilleur_modele']['forecast'].copy()
                    df_temp['Service'] = service
                    df_temp = df_temp.rename(columns={'ds': 'Date', 'yhat': 'Pr√©vision'})
                    df_toutes_previsions = pd.concat([df_toutes_previsions, df_temp[['Date', 'Service', 'Pr√©vision']]], ignore_index=True)
            
            if not df_toutes_previsions.empty:
                df_toutes_previsions.to_excel(writer, sheet_name='Pr√©visions D√©taill√©es', index=False)

            # Feuille 4: Graphiques HTML (nouveau)
            graphiques_html = []
            for service, data in self.resultats_prevision.items():
                graphique_html = self._generer_graphique_service(service, data)
                if graphique_html:
                    graphiques_html.append(f"<h2>{service}</h2>{graphique_html}")
            
            if graphiques_html:
                html_complet = f"""
                <html>
                <head><title>Graphiques de Pr√©visions</title></head>
                <body>
                <h1>Graphiques de Pr√©visions - Rapport Sant√©</h1>
                {''.join(graphiques_html)}
                </body>
                </html>
                """
                
                # Cr√©er un DataFrame avec le contenu HTML
                df_graphiques = pd.DataFrame([{'Contenu HTML': html_complet}])
                df_graphiques.to_excel(writer, sheet_name='Graphiques HTML', index=False)
            
        self.logger.info("‚úÖ Rapport Excel am√©lior√© g√©n√©r√© avec succ√®s.")
    
    def charger_et_preparer_donnees(self, fichier) -> None:
        success = self.charger_donnees(fichier)
        if success:
            self.donnees_mensuelles = self.df_data.rename(columns={
                'ds': 'date',
                'SERVICE': 'service',
                'y': 'valeur'
            })
        else:
            self.donnees_mensuelles = pd.DataFrame()

    def prevision_demande(self, periodes: int = 12) -> Dict[str, Any]:
        if self.df_data is None or self.df_data.empty:
            return {}
        
        resultats = self.calculer_previsions()
        
        previsions_formatted = {}
        for service, data in resultats.items():
            previsions_formatted[service] = data # Le dictionnaire est d√©j√† au bon format
        
        self.resultats_prevision = previsions_formatted
        return self.resultats_prevision