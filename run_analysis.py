# FileName: MultipleFiles/run_analysis.py
import os
import pickle
import pandas as pd
import sys
from pathlib import Path
from typing import Optional, Dict, Any, List, Union
from io import BytesIO

# Import des modules corrigÃ©s
from analytique_sante import AnalytiqueSante
from csv_transformer_script import HealthcareExcelTransformer # Assurez-vous que ce script est bien nommÃ© ainsi

def run_full_analysis(input_file_paths: Union[str, List[str]], annee_de_prevision: Optional[int] = None, output_dir: str = "data") -> None:
    """
    ExÃ©cute l'analyse complÃ¨te de bout en bout et sauvegarde les rÃ©sultats.
    VERSION CORRIGÃ‰E pour compatibilitÃ© avec analytique_sante.py amÃ©liorÃ©.
    Prend dÃ©sormais un ou plusieurs chemins de fichiers Excel en entrÃ©e.

    Args:
        input_file_paths (Union[str, List[str]]): Le chemin vers un fichier Excel brut ou une liste de chemins.
        annee_de_prevision (int, optional): L'annÃ©e pour laquelle gÃ©nÃ©rer les prÃ©visions.
                                            Les donnÃ©es jusqu'Ã  (annÃ©e_prÃ©v - 1) seront utilisÃ©es.
        output_dir (str): Le rÃ©pertoire pour sauvegarder le fichier de rÃ©sultats.
    """
    try:
        os.makedirs(output_dir, exist_ok=True)

        # Convertir input_file_paths en liste si c'est une chaÃ®ne unique
        if isinstance(input_file_paths, str):
            input_file_paths = [input_file_paths]

        print("="*70)
        print("ðŸ¥ ANALYSE COMPLÃˆTE DES DONNÃ‰ES DE SANTÃ‰ - VERSION SCORE COMPOSITE AMÃ‰LIORÃ‰E")
        print("="*70)
        print("Ã‰tape 1: Transformation des fichiers Excel en un CSV consolidÃ©...")

        all_transformed_data = []
        transformer = HealthcareExcelTransformer()

        for i, input_file_path in enumerate(input_file_paths):
            print(f"\nTraitement du fichier Excel ({i+1}/{len(input_file_paths)}): {os.path.basename(input_file_path)}")
            if not transformer.load_original_data(input_file_path):
                print(f"â›” Ã‰chec du chargement du fichier Excel {os.path.basename(input_file_path)}. Ce fichier sera ignorÃ©.")
                continue

            csv_data_part = transformer.transform()
            if csv_data_part is None or csv_data_part.empty:
                print(f"â›” Ã‰chec de la transformation pour {os.path.basename(input_file_path)}. Aucune donnÃ©e gÃ©nÃ©rÃ©e pour ce fichier.")
                print("ðŸ” VÃ©rifications possibles:")
                print("   - Le fichier Excel contient-il des colonnes de mois (JANVIER, FEVRIER, etc.) ?")
                print("   - Les donnÃ©es sont-elles dans le bon format (lignes = services, colonnes = mois) ?")
                print("   - Y a-t-il des donnÃ©es numÃ©riques dans les cellules ?")
                continue
            
            # Assurez-vous que la colonne 'date' est bien un datetime pour le tri futur
            csv_data_part['date'] = pd.to_datetime(csv_data_part['date'])
            all_transformed_data.append(csv_data_part)
            print(f"âœ… Transformation rÃ©ussie pour {os.path.basename(input_file_path)} - {len(csv_data_part)} lignes de donnÃ©es")

        if not all_transformed_data:
            print("â›” Aucune donnÃ©e valide n'a pu Ãªtre transformÃ©e Ã  partir des fichiers Excel fournis. ArrÃªt de l'exÃ©cution.")
            return

        # ConcatÃ©ner toutes les donnÃ©es transformÃ©es
        consolidated_csv_data = pd.concat(all_transformed_data, ignore_index=True)
        # Trier par date pour s'assurer que les donnÃ©es sont dans le bon ordre chronologique
        consolidated_csv_data = consolidated_csv_data.sort_values(by='date').reset_index(drop=True)

        print(f"\nâœ… Consolidation rÃ©ussie - Total de {len(consolidated_csv_data)} lignes de donnÃ©es sur toutes les annÃ©es.")
        print(f"ðŸ“Š Services dÃ©tectÃ©s dans l'ensemble consolidÃ©: {len(consolidated_csv_data['SERVICE'].unique())}")

        # Sauvegarder le fichier CSV consolidÃ© temporaire
        temp_csv_file = os.path.join(output_dir, f"consolidated_transformed_data.csv")
        consolidated_csv_data.to_csv(temp_csv_file, index=False)
        print(f"âœ… Fichier CSV consolidÃ© temporaire sauvegardÃ© Ã  : {os.path.basename(temp_csv_file)}")

        # Ã‰tape 2: Analyse prÃ©dictive avec score composite amÃ©liorÃ©
        print("\nÃ‰tape 2: Analyse prÃ©dictive avec score composite amÃ©liorÃ©...")
        analytique = AnalytiqueSante()
        # Charger les donnÃ©es consolidÃ©es
        analytique.charger_donnees(temp_csv_file, annee_cible=annee_de_prevision)

        if analytique.df_data is None or analytique.df_data.empty:
            print("â›” Les donnÃ©es d'entrÃ©e consolidÃ©es pour l'analyse sont vides ou invalides.")
            print("ðŸ” ProblÃ¨mes possibles:")
            print("   - Le fichier CSV consolidÃ© ne contient pas les bonnes colonnes")
            print("   - Aucun service reconnu dans les donnÃ©es consolidÃ©es")
            print("   - Format de date invalide")
            return

        print(f"âœ… DonnÃ©es consolidÃ©es chargÃ©es pour l'analyse: {len(analytique.df_data)} points")
        print(f"ðŸ“‹ Services reconnus: {analytique.df_data['SERVICE'].unique().tolist()}")

        print("\nðŸ”¬ Calcul des prÃ©visions avec score composite pondÃ©rÃ© amÃ©liorÃ©...")
        print("ðŸ“Š PondÃ©ration sanitaire utilisÃ©e:")
        print("   â€¢ sMAPE (PrÃ©cision relative symÃ©trique): 40%")
        print("   â€¢ MAE (Erreur absolue): 30%")
        print("   â€¢ RÂ² (Variance expliquÃ©e): 20%")
        print("   â€¢ RMSE (PÃ©nalitÃ© outliers): 10%")
        print("\nðŸŽ¯ Score composite bornÃ© entre 0.000 et 1.000")
        print("ðŸ”„ ARIMA robuste avec ordres multiples: (1,1,1), (0,1,1), (2,1,1), (1,1,0), (0,1,0)")
        print()

        previsions = analytique.calculer_previsions()

        services_avec_previsions = [s for s, data in previsions.items() if 'error' not in data]
        services_avec_erreurs = [s for s, data in previsions.items() if 'error' in data]

        print(f"âœ… PrÃ©visions rÃ©ussies pour {len(services_avec_previsions)} services")
        if services_avec_erreurs:
            print(f"âš ï¸ PrÃ©visions Ã©chouÃ©es pour {len(services_avec_erreurs)} services: {services_avec_erreurs}")

        # DÃ©terminer l'annÃ©e pour le nom du fichier de sortie
        # Si annee_de_prevision est fourni, l'utiliser. Sinon, utiliser la derniÃ¨re annÃ©e des donnÃ©es.
        if annee_de_prevision:
            output_year_str = str(annee_de_prevision)
        elif not consolidated_csv_data.empty:
            output_year_str = str(consolidated_csv_data['date'].dt.year.max())
        else:
            output_year_str = "unknown" # Fallback si aucune donnÃ©e

        analysis_output_path = os.path.join(output_dir, f"analyse_complete_{output_year_str}.pkl")
        with open(analysis_output_path, 'wb') as f:
            pickle.dump(previsions, f)
        print(f"âœ… RÃ©sultats de l'analyse sauvegardÃ©s Ã  : {os.path.basename(analysis_output_path)}")

        # Ã‰tape 3: GÃ©nÃ©ration du rapport Excel avec visualisations
        if services_avec_previsions:
            print("\nÃ‰tape 3: GÃ©nÃ©ration du rapport d'analyse Excel avec visualisations...")
            excel_output_path = os.path.join(output_dir, f"rapport_analyse_ameliore_{output_year_str}.xlsx")

            try:
                analytique.resultats_prevision = previsions
                with open(excel_output_path, 'wb') as f:
                    analytique.generer_rapport_excel_complet(f)
                print(f"âœ… Rapport d'analyse amÃ©liorÃ© gÃ©nÃ©rÃ© avec succÃ¨s Ã  : {os.path.basename(excel_output_path)}")
                print("ðŸ“ˆ Nouvelles fonctionnalitÃ©s du rapport:")
                print("   â€¢ Graphiques interactifs intÃ©grÃ©s (Plotly)")
                print("   â€¢ 4 feuilles : RÃ©sumÃ©, Comparaison, PrÃ©visions, Graphiques HTML")
                print("   â€¢ MÃ©triques de qualitÃ© complÃ¨tes")
            except Exception as e:
                print(f"âš ï¸ Erreur lors de la gÃ©nÃ©ration du rapport Excel: {e}")
        else:
            print("\nâš ï¸ Aucune prÃ©vision rÃ©ussie - rapport Excel non gÃ©nÃ©rÃ©")

        # RÃ©sumÃ© final avec scores composites amÃ©liorÃ©s
        print("\n" + "="*70)
        print("ðŸ“Š RÃ‰SUMÃ‰ DE L'ANALYSE AVEC SCORES COMPOSITES AMÃ‰LIORÃ‰S")
        print("="*70)
        print(f"ðŸ—‚ï¸ Fichiers gÃ©nÃ©rÃ©s dans '{output_dir}':")
        print(f"   - CSV consolidÃ© temporaire: {os.path.basename(temp_csv_file)}")
        print(f"   - RÃ©sultats analyse: {os.path.basename(analysis_output_path)}")
        if services_avec_previsions:
            print(f"   - Rapport Excel amÃ©liorÃ©: {os.path.basename(excel_output_path)}")

        print(f"\nðŸ“ˆ Services analysÃ©s: {len(services_avec_previsions)}/{len(previsions)}")

        # Tri des services par score composite pour affichage (scores maintenant 0-1)
        services_scores = []
        for service in services_avec_previsions:
            score_composite = previsions[service].get('score_composite', 0.0)
            services_scores.append((service, score_composite))

        services_scores.sort(key=lambda x: x[1], reverse=True)

        print("\nðŸ† Classement des services par Score Composite (0-1) :")
        for service, score in services_scores:
            # Classification qualitative du score
            if score >= 0.8:
                qualite = "ðŸŸ¢ Excellent"
            elif score >= 0.6:
                qualite = "ðŸ”µ Bon"
            elif score >= 0.4:
                qualite = "ðŸŸ¡ Moyen"
            else:
                qualite = "ðŸ”´ Faible"

            print(f"   - {service:<20}: {score:.3f}/1.000 ({qualite})")

        # Statistiques des scores
        if services_scores:
            scores = [score for _, score in services_scores]
            print(f"\nðŸ“Š Statistiques des scores:")
            print(f"   â€¢ Score moyen: {np.mean(scores):.3f}/1.000")
            print(f"   â€¢ Score mÃ©dian: {np.median(scores):.3f}/1.000")
            print(f"   â€¢ Meilleur score: {np.max(scores):.3f}/1.000")
            print(f"   â€¢ Score le plus faible: {np.min(scores):.3f}/1.000")

        print("="*70)

    except Exception as e:
        print(f"\nâ›” ERREUR CRITIQUE lors de l'exÃ©cution de l'analyse :")
        print(f"   {str(e)}")
        print(f"   Type d'erreur : {type(e).__name__}")
        import traceback
        print(f"\nðŸ› Trace complÃ¨te de l'erreur :")
        traceback.print_exc()

def main():
    """Fonction principale avec gestion amÃ©liorÃ©e des arguments."""
    if len(sys.argv) < 2:
        print("â›” Usage incorrect !")
        print("Usage: python run_analysis.py <chemin_vers_le_fichier_excel_1> [chemin_vers_le_fichier_excel_2 ...] [annee_de_prevision] [dossier_sortie]")
        print("\nExemple :")
        print("   python run_analysis.py LBS_matrice_2023.xlsx LBS_matrice_2024.xlsx LBS_matrice_2025.xlsx 2026")
        print("   python run_analysis.py LBS_matrice_2023.xlsx LBS_matrice_2024.xlsx LBS_matrice_2025.xlsx 2026 ./resultats")
        print("\nðŸ“‹ PrÃ©requis (installer si manquant) :")
        print("   pip install pandas numpy scikit-learn statsmodels prophet xlsxwriter plotly")
        sys.exit(1)

    # Les chemins des fichiers Excel sont les premiers arguments
    input_files = []
    annee_de_prevision = None
    output_dir = "data"

    # Parcourir les arguments pour identifier les fichiers, l'annÃ©e et le dossier de sortie
    args = sys.argv[1:]
    i = 0
    while i < len(args):
        arg = args[i]
        if arg.endswith(('.xlsx', '.xls')): # Si c'est un fichier Excel
            input_files.append(arg)
        elif arg.isdigit(): # Si c'est un nombre, on suppose que c'est l'annÃ©e de prÃ©vision
            annee_de_prevision = int(arg)
        else: # Sinon, on suppose que c'est le dossier de sortie
            output_dir = arg
        i += 1

    if not input_files:
        print("â›” Aucun fichier Excel d'entrÃ©e spÃ©cifiÃ©. Veuillez fournir au moins un fichier Excel.")
        sys.exit(1)

    run_full_analysis(input_files, annee_de_prevision, output_dir)

if __name__ == "__main__":
    import numpy as np # Assurez-vous que numpy est importÃ© si utilisÃ© dans main
    main()

